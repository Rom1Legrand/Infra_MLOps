# Infrastructure MLOps avec Airflow, MLflow, Jenkins & Streamlit

Une infrastructure MLOps compl√®te permettant de g√©rer le cycle de vie des mod√®les ML avec orchestration, tracking des exp√©riences, CI/CD et visualisation.

## üìã Pr√©requis

- Docker et Docker Compose
- Compte NeonDB (base de donn√©es PostgreSQL manag√©e)
- Compte AWS et bucket S3
- Compte Gmail pour l'envoi d'emails (avec authentification 2FA activ√©e)
- Git

## üèóÔ∏è Structure du Projet

```
.
‚îú‚îÄ‚îÄ docker-compose.yml
‚îú‚îÄ‚îÄ .env                     # Variables non-sensibles
‚îú‚îÄ‚îÄ .secrets                 # Variables sensibles (non versionn√©)
‚îú‚îÄ‚îÄ Dockerfile              # Dockerfile principal (Airflow)
‚îú‚îÄ‚îÄ Dockerfile.jenkins
‚îú‚îÄ‚îÄ Dockerfile.mlflow
‚îú‚îÄ‚îÄ Dockerfile.streamlit
‚îú‚îÄ‚îÄ requirements.txt           # Requirements Airflow
‚îú‚îÄ‚îÄ requirements.mlflow.txt
‚îú‚îÄ‚îÄ requirements.streamlit.txt
‚îú‚îÄ‚îÄ jenkins-requirements-optimized.txt
‚îú‚îÄ‚îÄ dags/                     # Dossier pour les DAGs Airflow
‚îú‚îÄ‚îÄ logs/                     # Logs Airflow
‚îú‚îÄ‚îÄ plugins/                  # Plugins Airflow
‚îî‚îÄ‚îÄ streamlit/
    ‚îî‚îÄ‚îÄ app.py               # Application Streamlit (obligatoire)
```

## ‚öôÔ∏è Configuration Initiale

### 1. Cr√©ation de R√©pertoires et fichiers (voir chap Installation et D√©marrage)
```bash
r√©p√©rtoire √† cr√©er : \dags \logs \plugins \streamlit
fichier √ß cr√©er :  app.py
```

### 2. Configuration S3
1. Cr√©er un bucket S3 sur AWS
2. Cr√©er les dossiers suivants dans le bucket:
   - `mlflow/` : Pour les artifacts MLflow
   - `data/` : Pour les donn√©es des pipelines
   - `models/` : Pour les mod√®les d√©ploy√©s

### 3. Configuration Gmail pour SMTP
1. Activer l'authentification 2 facteurs sur votre compte Gmail
2. G√©n√©rer un mot de passe d'application:
   - Aller dans Param√®tres du compte > S√©curit√©
   - S√©lectionner "Mots de passe des applications"
   - G√©n√©rer un nouveau mot de passe
   - Utiliser ce mot de passe dans EMAIL_PASSWORD du fichier .secrets

### 4. Configuration NeonDB
1. Cr√©er un compte sur NeonDB
2. Cr√©er une nouvelle base de donn√©es
3. R√©cup√©rer l'URL de connexion pour le fichier .secrets

## üîê Configuration des Variables d'Environnement

Le projet utilise deux fichiers de configuration :

### .env (Variables non-sensibles)
```bash
# System Configuration
AIRFLOW_UID=50000

# Service URLs & Ports
AIRFLOW_API_URL=http://airflow-webserver:8080
MLFLOW_TRACKING_URI=http://mlflow:5000
JENKINS_URL=http://jenkins:8080
JENKINS_OPTS="--prefix=/jenkins"
JENKINS_HOME=/var/jenkins_home

# Email Server Configuration
SMTP_SERVER=smtp.gmail.com
SMTP_PORT=587

# S3 Configuration
S3_BUCKET=your_bucket_name

# Service Default Users
AIRFLOW_USERNAME=admin
JENKINS_ADMIN_ID=admin
MLFLOW_TRACKING_USERNAME=admin

# MLflow Configuration
MLFLOW_DEFAULT_ARTIFACT_ROOT=s3://${S3_BUCKET}/mlflow/
```

### .secrets (Variables sensibles - ne pas versionner)
```bash
# Database Credentials
NEON_DATABASE_URL=your_neondb_url

# AWS Credentials
AWS_ACCESS_KEY_ID=your_key
AWS_SECRET_ACCESS_KEY=your_secret

# Email Credentials
EMAIL_USER=your.email@gmail.com
EMAIL_PASSWORD=your_app_password

# Service Passwords
AIRFLOW_PASSWORD=your_password
MLFLOW_TRACKING_PASSWORD=your_password
JENKINS_ADMIN_PASSWORD=your_password
```

## üöÄ Installation et D√©marrage

1. Cloner le repository :
```bash
git clone [your-repo-url]
cd [your-repo-name]
```

2. Cr√©er les r√©pertoires et fichiers n√©cessaires :
```bash
mkdir -p dags logs plugins streamlit
touch streamlit/app.py
```

3. Configurer les variables d'environnement :
- Copier `.env.example` vers `.env` et remplir les valeurs
- Copier `.secrets.example` vers `.secrets` et remplir les valeurs sensibles
- S'assurer que `.secrets` est dans `.gitignore`

4. Construire et d√©marrer les services :
```bash
docker-compose build
docker-compose up -d
```

## üåê Acc√®s aux Services

- Airflow : http://localhost:8080
  - Login : d√©fini dans .env/.secrets
- MLflow : http://localhost:5000
  - Login : d√©fini dans .env/.secrets
- Jenkins : http://localhost:8088
  - Login : d√©fini dans .env/.secrets
- Streamlit : http://localhost:8501

## üîß Architecture des Services

### Services Principaux
- **Airflow** (port 8080)
  - Orchestration des pipelines ML
  - Connexion √† NeonDB et S3
  - Configuration email SMTP
  - Gestion des DAGs
  - Variables d'environnement dans .env et .secrets

- **MLflow** (port 5000)
  - Tracking des exp√©riences
  - Stockage des m√©triques dans NeonDB
  - Stockage des artifacts dans S3
  - Interface web s√©curis√©e

- **Jenkins** (port 8088)
  - CI/CD pour les mod√®les ML
  - Support Python int√©gr√©
  - Plugins pr√©configur√©s
  - Monitoring des drifts

- **Streamlit** (port 8501)
  - Interface utilisateur simple
  - Un seul fichier app.py
  - Connexion √† NeonDB

### Services Auxiliaires (Airflow)
> Note : Ces services font partie de la configuration standard d'Airflow et sont maintenus pour une potentielle utilisation future.
- Redis : Message broker pour Celery
- Flower (port 5555) : Monitoring Celery
- Airflow Worker : Ex√©cuteur Celery
- Airflow Triggerer : Gestion des d√©clencheurs

## üìß Configuration Email

Le service utilise Gmail SMTP pour l'envoi d'emails :
- Configuration dans .env : SMTP_SERVER, SMTP_PORT
- Credentials dans .secrets : EMAIL_USER, EMAIL_PASSWORD
- N√©cessite l'authentification 2FA et un mot de passe d'application Gmail

## üõ†Ô∏è Maintenance

- Logs Airflow dans `./logs`
- Donn√©es Jenkins dans volume `jenkins_home`
- Backup automatique NeonDB
- Artifacts sur S3
- Tous les services utilisent des conteneurs ind√©pendants avec leurs propres requirements

## ‚ö†Ô∏è Notes Importantes

1. S√©curit√© :
   - Ne jamais commiter le fichier .secrets
   - Changer les mots de passe par d√©faut en production
   - Utiliser des secrets manager en production
   - Activer SSL pour toutes les connexions

2. D√©pendances :
   - Les requirements sont maintenus s√©par√©ment pour chaque service
   - Ne pas modifier les versions des d√©pendances (touchy!) si tout fonctionne
